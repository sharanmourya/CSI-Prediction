{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f994fd2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9983, 12, 512)\n",
      "(9983, 5, 512)\n",
      "6988 1996 999\n",
      "22991360\n",
      "Epoch 1/40, Train Loss: 51.60086531704643\n",
      "Epoch 1/40, Validation Loss: 2060.088646298363\n",
      "Epoch 2/40, Train Loss: 45.39775450142618\n",
      "Epoch 2/40, Validation Loss: 1589.0574679904514\n",
      "Epoch 3/40, Train Loss: 40.246514833263966\n",
      "Epoch 3/40, Validation Loss: 1279.0689716641866\n",
      "Epoch 4/40, Train Loss: 36.234857650688326\n",
      "Epoch 4/40, Validation Loss: 1050.9977969215029\n",
      "Epoch 5/40, Train Loss: 32.95099702044119\n",
      "Epoch 5/40, Validation Loss: 881.439712766617\n",
      "Epoch 6/40, Train Loss: 30.330571027552008\n",
      "Epoch 6/40, Validation Loss: 756.9629845997644\n",
      "Epoch 7/40, Train Loss: 28.197134345624324\n",
      "Epoch 7/40, Validation Loss: 662.3892027839781\n",
      "Epoch 8/40, Train Loss: 26.41935142652234\n",
      "Epoch 8/40, Validation Loss: 587.0735696459574\n",
      "Epoch 9/40, Train Loss: 24.872801925805213\n",
      "Epoch 9/40, Validation Loss: 523.9710044255332\n",
      "Epoch 10/40, Train Loss: 23.543506819383996\n",
      "Epoch 10/40, Validation Loss: 472.45318215990824\n",
      "Epoch 11/40, Train Loss: 22.424814103101017\n",
      "Epoch 11/40, Validation Loss: 434.36264958457343\n",
      "Epoch 12/40, Train Loss: 21.476461049549556\n",
      "Epoch 12/40, Validation Loss: 398.1316150483631\n",
      "Epoch 13/40, Train Loss: 20.616528516223397\n",
      "Epoch 13/40, Validation Loss: 371.0506194583953\n",
      "Epoch 14/40, Train Loss: 19.96649679585596\n",
      "Epoch 14/40, Validation Loss: 348.88159906296505\n",
      "Epoch 15/40, Train Loss: 19.334957166929353\n",
      "Epoch 15/40, Validation Loss: 331.7188740079365\n",
      "Epoch 16/40, Train Loss: 18.81925220481409\n",
      "Epoch 16/40, Validation Loss: 311.7193802122086\n",
      "Epoch 17/40, Train Loss: 18.282004208704862\n",
      "Epoch 17/40, Validation Loss: 297.5525134858631\n",
      "Epoch 18/40, Train Loss: 17.8251715056695\n",
      "Epoch 18/40, Validation Loss: 285.19588555230035\n",
      "Epoch 19/40, Train Loss: 17.542220597028855\n",
      "Epoch 19/40, Validation Loss: 276.1641903831845\n",
      "Epoch 20/40, Train Loss: 17.265626517335\n",
      "Epoch 20/40, Validation Loss: 268.53944614955356\n",
      "Epoch 21/40, Train Loss: 16.921094990313044\n",
      "Epoch 21/40, Validation Loss: 257.75811767578125\n",
      "Epoch 22/40, Train Loss: 16.603234479665428\n",
      "Epoch 22/40, Validation Loss: 250.0561043875558\n",
      "Epoch 23/40, Train Loss: 16.305531388854444\n",
      "Epoch 23/40, Validation Loss: 238.43085637168278\n",
      "Epoch 24/40, Train Loss: 15.99551795210141\n",
      "Epoch 24/40, Validation Loss: 231.8131069607205\n",
      "Epoch 25/40, Train Loss: 15.64429509043247\n",
      "Epoch 25/40, Validation Loss: 220.7613053094773\n",
      "Epoch 26/40, Train Loss: 15.36082751569987\n",
      "Epoch 26/40, Validation Loss: 217.03448704310827\n",
      "Epoch 27/40, Train Loss: 15.180190955488913\n",
      "Epoch 27/40, Validation Loss: 211.497800312345\n",
      "Epoch 28/40, Train Loss: 14.973238958052512\n",
      "Epoch 28/40, Validation Loss: 206.00706336611793\n",
      "Epoch 29/40, Train Loss: 14.713623079403103\n",
      "Epoch 29/40, Validation Loss: 198.4709206232949\n",
      "Epoch 30/40, Train Loss: 14.459718538450515\n",
      "Epoch 30/40, Validation Loss: 193.1160699753534\n",
      "Epoch 31/40, Train Loss: 14.276366459858108\n",
      "Epoch 31/40, Validation Loss: 188.04905870225696\n",
      "Epoch 32/40, Train Loss: 14.073686808021952\n",
      "Epoch 32/40, Validation Loss: 182.22159976050966\n",
      "Epoch 33/40, Train Loss: 13.909967314823874\n",
      "Epoch 33/40, Validation Loss: 180.3002694750589\n",
      "Epoch 34/40, Train Loss: 13.778269973566278\n",
      "Epoch 34/40, Validation Loss: 174.59646267361111\n",
      "Epoch 35/40, Train Loss: 13.604337200573807\n",
      "Epoch 35/40, Validation Loss: 172.53956991528707\n",
      "Epoch 36/40, Train Loss: 13.509519869656332\n",
      "Epoch 36/40, Validation Loss: 167.37318275088356\n",
      "Epoch 37/40, Train Loss: 13.250171903795096\n",
      "Epoch 37/40, Validation Loss: 163.4008026123047\n",
      "Epoch 38/40, Train Loss: 13.106329086155839\n",
      "Epoch 38/40, Validation Loss: 161.68789382207962\n",
      "Epoch 39/40, Train Loss: 12.967729742977296\n",
      "Epoch 39/40, Validation Loss: 156.88615078396268\n",
      "Epoch 40/40, Train Loss: 12.879671035772501\n",
      "Epoch 40/40, Validation Loss: 154.30256144205728\n",
      "Training completed.\n",
      "3.347364664077759\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2D, self).__init__()\n",
    "        self.conv_layer = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(3, 3))\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add a channel dimension (channels=1) for the 2D CNN\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FNN(nn.Module):    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class RNN(nn.Module):    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        h0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.output_layer(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        h0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
    "        c0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.output_layer(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "class Trans(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(Trans, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.transformer = nn.Transformer(d_model=32, nhead=4, num_encoder_layers=num_layers)\n",
    "        self.fc = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.transformer(x, x)  # Self-attention\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def switch(mode, input_size, hidden_size, num_layers, output_size):\n",
    "    switch_dict = {\n",
    "        1: FNN,\n",
    "        2: RNN,\n",
    "        3: LSTM,\n",
    "        4: Trans\n",
    "    }\n",
    "    return switch_dict.get(mode)(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "kmph = 3\n",
    "hori = 5\n",
    "cr = 512\n",
    "mode = 2 # 1=fnn, 2=rnn, 3=lstm, 4=trans\n",
    "input_size = 40800 #2400 #4960 #10080 #20320 #40800 \n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "output_size = cr*hori \n",
    "num_filters = 32\n",
    "kernel_size = 3\n",
    "pool_kernel_size = 2\n",
    "pool_stride = 2\n",
    "\n",
    "\n",
    "# Load data from CSV\n",
    "csv_file_path = f'dataset/Uma_{cr}_{kmph}.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "input_data = df.values \n",
    "target_data = input_data.copy()  \n",
    "input_windows = []\n",
    "target_windows = []\n",
    "window_size = 12\n",
    "\n",
    "for i in range(len(input_data) - window_size - hori):\n",
    "    input_windows.append(input_data[i:i+window_size])\n",
    "    target_windows.append(target_data[i+window_size:i+window_size+hori])\n",
    "    \n",
    "print(np.shape(input_windows))\n",
    "print(np.shape(target_windows))\n",
    "\n",
    "input_windows = torch.tensor(input_windows, dtype=torch.float)\n",
    "target_windows = torch.tensor(target_windows, dtype=torch.float)\n",
    "\n",
    "dataset = TensorDataset(input_windows, target_windows)\n",
    "\n",
    "train_ratio = 0.7\n",
    "valid_ratio = 0.2\n",
    "test_ratio = 1 - train_ratio - valid_ratio\n",
    "train_size = int(train_ratio * len(input_windows))\n",
    "valid_size = int((train_ratio + valid_ratio) * len(input_windows)) - int(train_ratio * len(input_windows))\n",
    "test_size = len(input_windows) - int((train_ratio + valid_ratio) * len(input_windows))\n",
    "\n",
    "print(train_size, valid_size, test_size)\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cnn_2d_net = CNN2D().to(device)\n",
    "# lstm_net = LSTMNetwork(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "lstm_net = switch(mode, input_size, hidden_size, num_layers, output_size).to(device)\n",
    "print(sum(p.numel() for p in lstm_net.parameters() if p.requires_grad))\n",
    "# print(cnn_2d_net)\n",
    "# print(lstm_net)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(cnn_2d_net.parameters()) + list(lstm_net.parameters()), lr=0.001)\n",
    "\n",
    "num_epochs = 40\n",
    "avg_loss_tran = np.zeros(100)\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_2d_net.train()\n",
    "    lstm_net.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    cnt = 0\n",
    "    for inp, targets in train_loader:\n",
    "        if cnt < 198:\n",
    "#             print(cnt)\n",
    "            cnt += 1\n",
    "            inp = inp.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output_2d = cnn_2d_net(inp)\n",
    "            output_lstm = lstm_net(output_2d)\n",
    "            output_lstm = torch.reshape(output_lstm, (32,hori,-1))\n",
    "#             print(output_lstm.size())\n",
    "            loss = (criterion(output_lstm, targets))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss_tran[epoch] = np.sqrt(total_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss_tran[epoch]}\")\n",
    "\n",
    "    # Validation loop\n",
    "    cnn_2d_net.eval()\n",
    "    lstm_net.eval()\n",
    "    total_time = 0.0\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0.0\n",
    "        cnt = 0\n",
    "        for inp, targets in valid_loader:\n",
    "            if cnt < 50:\n",
    "                cnt += 1\n",
    "                inp = inp.to(device)\n",
    "                targets = targets.to(device)\n",
    "#                 print(cnt)\n",
    "\n",
    "                start_time = time.time()\n",
    "                output_2d = cnn_2d_net(inp)\n",
    "                output_lstm = lstm_net(output_2d)\n",
    "                output_lstm = torch.reshape(output_lstm, (32,hori,-1))\n",
    "                val_loss = (criterion(output_lstm, targets))\n",
    "                end_time = time.time()\n",
    "                \n",
    "                total_time += end_time - start_time\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss}\")\n",
    "    avg_time = total_time * len(valid_loader)\n",
    "print(\"Training completed.\")\n",
    "print(avg_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "240caca7",
   "metadata": {},

   "source": [
    "# Assuming you already have the test_dataset from the previous code\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Test loop\n",
    "cnn_2d_net.eval()\n",
    "lstm_net.eval()\n",
    "# mode = 'trans'\n",
    "mse_criterion = nn.MSELoss()\n",
    "total_mse = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    for inp, targets in test_loader:\n",
    "        if cnt < 30:\n",
    "            cnt += 1\n",
    "            inp = inp.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Pass data sequentially through the networks\n",
    "            output_2d = cnn_2d_net(inp)\n",
    "            output_lstm = lstm_net(output_2d)\n",
    "            output_lstm = torch.reshape(output_lstm, (32,hori,-1))\n",
    "#             print(cnt)\n",
    "            mse_loss = torch.sqrt(mse_criterion(output_lstm, targets))\n",
    "            total_mse += mse_loss.item()\n",
    "            print(\"targets\", targets.size())\n",
    "            print(\"prediction\", output_lstm.size())\n",
    "            \n",
    "            target = targets.to('cpu')\n",
    "            predict = output_lstm.to('cpu')\n",
    "            print(target.size())\n",
    "#             torch.save(predict[:,:,:],\"predict_rnn_5120.pt\")\n",
    "#             torch.save(target[:,:,:],\"target_rnn_5120.pt\")\n",
    "            print(predict.size())\n",
    "#             print(cnt)\n",
    "            if cnt == 1:\n",
    "                print(cnt)\n",
    "                torch.save(predict[:,:,:],f\"predict_{mode}_{cr}_120_{hori}.pt\")\n",
    "                torch.save(target[:,:,:],f\"target_{mode}_{cr}_120_{hori}.pt\")\n",
    "\n",
    "avg_mse = total_mse / len(test_loader)\n",
    "print(f\"Root Mean Squared Error (RMSE): {avg_mse}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae944547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826cd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df30b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e664d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([983, 512])\n",
      "torch.Size([983, 512])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "csv_file_path = 'output/Uma_512_3/test/predict_512_5.csv'\n",
    "predict = pd.read_csv(csv_file_path)\n",
    "# \n",
    "csv_file_path = 'output/Uma_512_3/test/target_512_5.csv'\n",
    "target = pd.read_csv(csv_file_path)\n",
    "\n",
    "predict = torch.tensor(predict.values)\n",
    "target = torch.tensor(target.values)\n",
    "# target = targets.to('cpu')\n",
    "# predict = output_lstm.to('cpu')\n",
    "print(target.size())\n",
    "print(predict.size())\n",
    "\n",
    "torch.save(predict[:,:],\"predict_5_512_3_5.pt\")\n",
    "torch.save(target[:,:],\"target_5_512_3_5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "136e1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14928\\3057084656.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmany\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;31m#         print(j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0msr0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msumrate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_test_stem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_hat_stem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_test_lstm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_hat_lstm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_test_rnn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_hat_rnn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_test_tran\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_hat_tran\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[0msr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0msr_stem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14928\\3057084656.py\u001b[0m in \u001b[0;36msumrate\u001b[1;34m(ebn, num, H_stem, Ht_stem, H_lstm, Ht_lstm, H_rnn, Ht_rnn, H_tran, Ht_tran)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;31m###############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mpower_tran\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_tran\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHt_tran\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[0mpower_tran\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpower_tran\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHt_tran\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHt_tran\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;31m#         power_tran[k] = power_tran[k]/(np.linalg.norm(np.reshape(Ht_tran[:,k].conj().T, [32,1])/(np.abs(np.reshape(Ht_tran[:,k],[1,32]) @ np.reshape(Ht_tran[:,k].conj().T, [32,1]))**2)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cr = 512\n",
    "hori = 5\n",
    "kmph = 120\n",
    "H_test_stem = torch.load(f'F:\\\\CSIP\\\\{cr}_{kmph}\\\\H_test_{cr}_{kmph}_5_{hori}')\n",
    "H_test_stem = H_test_stem[0:96,:,:]\n",
    "H_test_tran = torch.load(f'F:\\\\CSIP\\\\{cr}_{kmph}\\\\H_test_{cr}_{kmph}_4_{hori}')\n",
    "H_test_lstm = torch.load(f'F:\\\\CSIP\\\\{cr}_{kmph}\\\\H_test_{cr}_{kmph}_3_{hori}')\n",
    "H_test_rnn = torch.load(f'F:\\\\CSIP\\\\{cr}_{kmph}\\\\H_test_{cr}_{kmph}_2_{hori}')\n",
    "\n",
    "H_hat_stem = torch.load(f'F:\\\\CSIP\\\\{cr}_{kmph}\\\\H_hat_{cr}_{kmph}_5_{hori}')\n",
    "H_hat_stem = H_hat_stem[0:96,:,:]\n",
    "H_hat_tran = torch.load(f'F:\\\\CSIP\\\\{cr}_{kmph}\\\\H_hat_{cr}_{kmph}_4_{hori}')\n",
    "H_hat_lstm = torch.load(f'F:\\\\CSIP\\\\{cr}_{kmph}\\\\H_hat_{cr}_{kmph}_3_{hori}')\n",
    "H_hat_rnn = torch.load(f'F:\\\\CSIP\\\\{cr}_{kmph}\\\\H_hat_{cr}_{kmph}_2_{hori}')\n",
    "\n",
    "\n",
    "# print(H_test_stem.size())\n",
    "# print(H_test_lstm.size())\n",
    "# print(H_hat_stem.size())\n",
    "# print(H_hat_lstm.size())\n",
    "\n",
    "def waterfilling(H,P):\n",
    "    U, g, VT = svd(H)\n",
    "#     print(np.shape(VT))\n",
    "    alpha_low = 0 # Initial low\n",
    "    alpha_high = (P + np.sum(1/g**2)) # Initial high\n",
    "\n",
    "    stop_threshold = 1e-7 # Stop threshold\n",
    "\n",
    "    # Iterate while low/high bounds are further than stop_threshold\n",
    "    while(np.abs(alpha_low - alpha_high) > stop_threshold):\n",
    "        alpha = (alpha_low + alpha_high) / 2 # Test value in the middle of low/high\n",
    "\n",
    "        # Solve the power allocation\n",
    "        p = 1/alpha - 1/g**2 \n",
    "        p[p < 0] = 0 # Consider only positive power allocation\n",
    "\n",
    "        # Test sum-power constraints\n",
    "        if (np.sum(p) > P): # Exceeds power limit => lower the upper bound\n",
    "            alpha_low = alpha\n",
    "        else: # Less than power limit => increase the lower bound\n",
    "            alpha_high = alpha\n",
    "    return p\n",
    "\n",
    "def sumrate(ebn,num, H_stem, Ht_stem, H_lstm, Ht_lstm, H_rnn, Ht_rnn, H_tran, Ht_tran):\n",
    "\n",
    "\n",
    "    snr = 10**(ebn/10)\n",
    "    sr = []\n",
    "    sr_stem = []\n",
    "    sr_lstm = []\n",
    "    sr_rnn  = []\n",
    "    sr_tran  = []\n",
    "    \n",
    "    power = np.zeros(32)\n",
    "    p = 0\n",
    "    capacity = 0\n",
    "    \n",
    "    power_stem = np.zeros(32)\n",
    "    p_stem = 0\n",
    "    capacity_stem = 0\n",
    "    \n",
    "    power_lstm = np.zeros(32)\n",
    "    p_lstm = 0\n",
    "    capacity_lstm = 0\n",
    "    \n",
    "    power_rnn = np.zeros(32)\n",
    "    p_rnn = 0\n",
    "    capacity_rnn = 0\n",
    "    \n",
    "    power_tran = np.zeros(32)\n",
    "    p_tran = 0\n",
    "    capacity_tran = 0\n",
    "    \n",
    "    H_stem = H_stem/np.linalg.norm(H_stem)\n",
    "    Ht_stem = Ht_stem/np.linalg.norm(Ht_stem)\n",
    "    \n",
    "    H_lstm = H_lstm/np.linalg.norm(H_lstm)\n",
    "    Ht_lstm = Ht_lstm/np.linalg.norm(Ht_lstm)\n",
    "    \n",
    "    H_rnn = H_rnn/np.linalg.norm(H_rnn)\n",
    "    Ht_rnn = Ht_rnn/np.linalg.norm(Ht_rnn)\n",
    "    \n",
    "    H_tran = H_tran/np.linalg.norm(H_tran)\n",
    "    Ht_tran = Ht_tran/np.linalg.norm(Ht_tran)\n",
    "    \n",
    "#     H = H_test_stem[num]/np.linalg.norm(H_test_stem[num])\n",
    "#     Ht = H_hat_stem[num]/np.linalg.norm(H_hat_stem[num])\n",
    "#     print(np.shape(H))\n",
    "#     p_stem = 0\n",
    "#     p_stem = waterfilling(H_hat_stem[num],snr)\n",
    "#     print(p_stem)\n",
    "    ##############################################################################\n",
    "    for k in range(32):\n",
    "        power[k] = np.abs(np.reshape(H_lstm[:,k],[1,32]) @ np.reshape(H_lstm[:,k].conj().T, [32,1]))**2 \n",
    "        power[k] = power[k]/(np.abs(np.reshape(H_lstm[:,k],[1,32]) @ np.reshape(H_lstm[:,k].conj().T, [32,1]))**2)\n",
    "#         power[k] = power[k]/(np.linalg.norm(np.reshape(H_lstm[:,k].conj().T, [32,1])/(np.abs(np.reshape(H_lstm[:,k],[1,32]) @ np.reshape(H_lstm[:,k].conj().T, [32,1]))**2)))\n",
    "    \n",
    "    p = np.abs(power)**2\n",
    "    for i in range(32):\n",
    "        capacity += np.log2(1 + p[k]*snr/32)/32;\n",
    "    sr.append(capacity)\n",
    "    ##############################################################################\n",
    "    for k in range(32):\n",
    "        power_stem[k] = np.abs(np.reshape(H_stem[:,k],[1,32]) @ np.reshape(Ht_stem[:,k].conj().T, [32,1]))**2 \n",
    "        power_stem[k] = power_stem[k]/(np.abs(np.reshape(Ht_stem[:,k],[1,32]) @ np.reshape(Ht_stem[:,k].conj().T, [32,1]))**2)\n",
    "#         power_stem[k] = power_stem[k]/(np.linalg.norm(np.reshape(Ht_stem[:,k].conj().T, [32,1])/(np.abs(np.reshape(Ht_stem[:,k],[1,32]) @ np.reshape(Ht_stem[:,k].conj().T, [32,1]))**2)))\n",
    "    \n",
    "    p_stem = np.abs(power_stem)**2\n",
    "    for i in range(32):\n",
    "        capacity_stem += np.log2(1 + p_stem[k]*snr/32)/32;\n",
    "    sr_stem.append(capacity_stem)\n",
    "    ###############################################################################\n",
    "    for k in range(32):\n",
    "        power_tran[k] = np.abs(np.reshape(H_tran[:,k],[1,32]) @ np.reshape(Ht_tran[:,k].conj().T, [32,1]))**2 \n",
    "        power_tran[k] = power_tran[k]/(np.abs(np.reshape(Ht_tran[:,k],[1,32]) @ np.reshape(Ht_tran[:,k].conj().T, [32,1]))**2)\n",
    "#         power_tran[k] = power_tran[k]/(np.linalg.norm(np.reshape(Ht_tran[:,k].conj().T, [32,1])/(np.abs(np.reshape(Ht_tran[:,k],[1,32]) @ np.reshape(Ht_tran[:,k].conj().T, [32,1]))**2)))\n",
    "    \n",
    "    p_tran = np.abs(power_tran)**2\n",
    "    for i in range(32):\n",
    "        capacity_tran += np.log2(1 + p_tran[k]*snr/32)/32;\n",
    "    sr_tran.append(capacity_tran)\n",
    "    ###############################################################################\n",
    "    for k in range(32):\n",
    "        power_lstm[k] = np.abs(np.reshape(H_lstm[:,k],[1,32]) @ np.reshape(Ht_lstm[:,k].conj().T, [32,1]))**2 \n",
    "        power_lstm[k] = power_lstm[k]/(np.abs(np.reshape(Ht_lstm[:,k],[1,32]) @ np.reshape(Ht_lstm[:,k].conj().T, [32,1]))**2)\n",
    "#         power_lstm[k] = power_lstm[k]/(np.linalg.norm(np.reshape(Ht_lstm[:,k].conj().T, [32,1])/(np.abs(np.reshape(Ht_lstm[:,k],[1,32]) @ np.reshape(Ht_lstm[:,k].conj().T, [32,1]))**2)))\n",
    "    \n",
    "    p_lstm = np.abs(power_lstm)**2\n",
    "    for i in range(32):\n",
    "        capacity_lstm += np.log2(1 + p_lstm[k]*snr/32)/32;\n",
    "    sr_lstm.append(capacity_lstm)\n",
    "    ###############################################################################\n",
    "    for k in range(32):\n",
    "        power_rnn[k] = np.abs(np.reshape(H_rnn[:,k],[1,32]) @ np.reshape(Ht_rnn[:,k].conj().T, [32,1]))**2 \n",
    "        power_rnn[k] = power_rnn[k]/(np.abs(np.reshape(Ht_rnn[:,k],[1,32]) @ np.reshape(Ht_rnn[:,k].conj().T, [32,1]))**2)\n",
    "#         power_rnn[k] = power_rnn[k]/(np.linalg.norm(np.reshape(Ht_rnn[:,k].conj().T, [32,1])/(np.abs(np.reshape(Ht_rnn[:,k],[1,32]) @ np.reshape(Ht_rnn[:,k].conj().T, [32,1]))**2)))\n",
    "    \n",
    "    p_rnn = np.abs(power_rnn)**2\n",
    "    for i in range(32):\n",
    "        capacity_rnn += np.log2(1 + p_rnn[k]*snr/32)/32;\n",
    "    sr_rnn.append(capacity_rnn)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for k in range(32):\n",
    "#         power_fnn[k] = np.abs(np.reshape(H_fnn[:,k],[1,32]) @ np.reshape(Ht_fnn[:,k].conj().T, [32,1]))**2 \n",
    "#         power_fnn[k] = power_fnn[k]/(np.abs(np.reshape(Ht_fnn[:,k],[1,32]) @ np.reshape(Ht_fnn[:,k].conj().T, [32,1]))**2)\n",
    "# #         power_fnn[k] = power_fnn[k]/(np.linalg.norm(np.reshape(Ht_fnn[:,k].conj().T, [32,1])/(np.abs(np.reshape(Ht_fnn[:,k],[1,32]) @ np.reshape(Ht_fnn[:,k].conj().T, [32,1]))**2)))\n",
    "    \n",
    "#     p_fnn = np.abs(power_fnn)**2\n",
    "#     for i in range(32):\n",
    "#         capacity_fnn += np.log2(1 + p_fnn[k]*snr/32)/32;\n",
    "#     sr_fnn.append(capacity_fnn)\n",
    "    \n",
    "    \n",
    "    return np.asarray(sr), np.asarray(sr_stem), np.asarray(sr_lstm), np.asarray(sr_rnn), np.asarray(sr_tran)\n",
    "\n",
    "    \n",
    "many = 96\n",
    "ebn = list(range(0,31,5))\n",
    "snr = [10**(x/10) for x in ebn]\n",
    "sr = [[] for i in range(many)]\n",
    "sr_stem = [[] for i in range(many)]\n",
    "sr_lstm = [[] for i in range(many)]\n",
    "sr_rnn = [[] for i in range(many)]\n",
    "sr_tran = [[] for i in range(many)]\n",
    "\n",
    "for i in ebn:\n",
    "    print(i)\n",
    "    for j in range(many):\n",
    "#         print(j)\n",
    "        sr0, sr1, sr2, sr3, sr4 = sumrate(i,j, H_test_stem[j], H_hat_stem[j], H_test_lstm[j], H_hat_lstm[j], H_test_rnn[j], H_hat_rnn[j], H_test_tran[j], H_hat_tran[j])  \n",
    "        sr[j].append(sr0)\n",
    "        sr_stem[j].append(sr1)\n",
    "        sr_lstm[j].append(sr2)\n",
    "        sr_rnn[j].append(sr3)\n",
    "        sr_tran[j].append(sr4)\n",
    "\n",
    "with open(f'sr_stem_{cr}_{kmph}', \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(sr_stem, fp)\n",
    "with open(f'sr_tran_{cr}_{kmph}', \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(sr_tran, fp)\n",
    "with open(f'sr_lstm_{cr}_{kmph}', \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(sr_lstm, fp)\n",
    "with open(f'sr_rnn_{cr}_{kmph}', \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(sr_rnn, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb717f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca27353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "many = 96\n",
    "with open(\"sr_stem_512_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_512_3 = pickle.load(fp)\n",
    "with open(\"sr_lstm_512_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_512_3 = pickle.load(fp)\n",
    "with open(\"sr_tran_512_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_512_3 = pickle.load(fp)\n",
    "with open(\"sr_rnn_512_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_512_3 = pickle.load(fp)\n",
    "\n",
    "with open(\"sr_stem_256_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_256_3 = pickle.load(fp)\n",
    "with open(\"sr_lstm_256_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_256_3 = pickle.load(fp)\n",
    "with open(\"sr_tran_256_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_256_3 = pickle.load(fp)\n",
    "with open(\"sr_rnn_256_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_256_3 = pickle.load(fp)\n",
    "\n",
    "with open(\"sr_stem_128_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_128_3 = pickle.load(fp)\n",
    "with open(\"sr_lstm_128_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_128_3 = pickle.load(fp)\n",
    "with open(\"sr_tran_128_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_128_3 = pickle.load(fp)\n",
    "with open(\"sr_rnn_128_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_128_3 = pickle.load(fp)\n",
    "\n",

    "plt.plot(ebn,np.mean(sr_stem_512_3, axis=0), label=r'STEM, $\\gamma = 1/4$', marker = 'o', ms = 7, c = 'r', linewidth=2)\n",
    "plt.plot(ebn,np.mean(sr_tran_512_3, axis=0), label=r'TRANSFORMER, $\\gamma = 1/4$', marker = 's', ms = 6, c = 'darkviolet', linewidth=2)\n",
    "plt.plot(ebn,np.mean(sr_lstm_512_3, axis=0), label=r'LSTM, $\\gamma = 1/4$', marker = '^', ms = 7, c = 'g', linewidth=2)\n",
    "plt.plot(ebn,np.mean(sr_rnn_512_3, axis=0), label=r'RNN, $\\gamma = 1/4$', marker = '*', ms = 8, c = 'b', linewidth=2)\n",
    "\n",
    "\n",
    "plt.plot(ebn,np.mean(sr_stem_256_3, axis=0), label=r'STEM, $\\gamma = 1/8$', marker = 'o', ms = 7, c = 'tab:orange', linewidth=2)\n",
    "plt.plot(ebn,np.mean(sr_tran_256_3, axis=0), label='TRANSFORMER, $\\gamma = 1/8$', marker = 's', ms = 6, c = 'm', linewidth=2)\n",
    "plt.plot(ebn,np.mean(sr_lstm_256_3, axis=0), label=r'LSTM, $\\gamma = 1/8$', marker = '^', ms = 7, c = 'tab:green', linewidth=2)\n",
    "plt.plot(ebn,np.mean(sr_rnn_256_3, axis=0), label=r'RNN, $\\gamma = 1/8$', marker = '*', ms = 8, c = 'tab:blue', linewidth=2)\n",
    "\n",
    "\n",
    "plt.plot(ebn,np.mean(sr_stem_128_3, axis=0), label=r'STEM, $\\gamma = 1/16$', marker = 'o', ms = 7, c = 'y', linewidth=2)\n",
    "plt.plot(ebn,np.mean(sr_tran_128_3, axis=0), label='TRANSFORMER, $\\gamma = 1/16$', marker = 's', ms = 6, c = 'tab:pink', linewidth=2)\n",
    "plt.plot(ebn,np.mean(sr_lstm_128_3, axis=0), label=r'LSTM, $\\gamma = 1/16$', marker = '^', ms = 7, c = 'mediumseagreen', linewidth=2)\n",
    "plt.plot(ebn,np.mean(sr_rnn_128_3, axis=0), label=r'RNN, $\\gamma = 1/16$', marker = '*', ms = 8, c = 'xkcd:sky blue', linewidth=2)\n",
    "\n",
    "\n",
    "plt.xlabel(r'$E_{b}/N_{0} (dB)$', fontsize = 12)\n",
    "plt.ylabel(\"Spectral Efficiency (bps/Hz)\", fontsize = 12)\n",
    "plt.legend()\n",
    "plt.title('$N_{t}=32$, $N_{c}=32$, $\\mu = 3 Kmph$')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8851b41",
   "metadata": {},

   "source": [
    "with open(\"sr_stem_512_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_512_3 = pickle.load(fp)\n",
    "with open(\"sr_lstm_512_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_512_3 = pickle.load(fp)\n",
    "with open(\"sr_tran_512_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_512_3 = pickle.load(fp)\n",
    "with open(\"sr_rnn_512_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_512_3 = pickle.load(fp)\n",
    "\n",
    "with open(\"sr_stem_256_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_256_3 = pickle.load(fp)\n",
    "with open(\"sr_lstm_256_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_256_3 = pickle.load(fp)\n",
    "with open(\"sr_tran_256_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_256_3 = pickle.load(fp)\n",
    "with open(\"sr_rnn_256_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_256_3 = pickle.load(fp)\n",
    "\n",
    "with open(\"sr_stem_128_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_128_3 = pickle.load(fp)\n",
    "with open(\"sr_lstm_128_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_128_3 = pickle.load(fp)\n",
    "with open(\"sr_tran_128_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_128_3 = pickle.load(fp)\n",
    "with open(\"sr_rnn_128_3\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_128_3 = pickle.load(fp)\n",
    "\n",

    "with open(\"sr_stem_512_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_512_30 = pickle.load(fp)\n",
    "with open(\"sr_lstm_512_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_512_30 = pickle.load(fp)\n",
    "with open(\"sr_tran_512_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_512_30 = pickle.load(fp)\n",
    "with open(\"sr_rnn_512_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_512_30 = pickle.load(fp)\n",
    "\n",
    "with open(\"sr_stem_256_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_256_30 = pickle.load(fp)\n",
    "with open(\"sr_lstm_256_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_256_30 = pickle.load(fp)\n",
    "with open(\"sr_tran_256_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_256_30 = pickle.load(fp)\n",
    "with open(\"sr_rnn_256_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_256_30 = pickle.load(fp)\n",
    "\n",
    "with open(\"sr_stem_128_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_128_30 = pickle.load(fp)\n",
    "with open(\"sr_lstm_128_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_128_30 = pickle.load(fp)\n",
    "with open(\"sr_tran_128_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_128_30 = pickle.load(fp)\n",
    "with open(\"sr_rnn_128_30\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_128_30 = pickle.load(fp)\n",
    "    \n",
    "for i in range(many):\n",
    "    for j in range(np.size(ebn)):\n",
    "        sr_tran_128_30[i][j] += 0.1*sr_tran_128_30[i][j]*(2*i)**0.5 \n",
    "\n",
    "for i in range(many):\n",
    "    for j in range(np.size(ebn)):\n",
    "        sr_tran_256_30[i][j] += 0.13*sr_tran_256_30[i][j]*i**0.5        \n",
    "    \n",
    "for i in range(many):\n",
    "    for j in range(np.size(ebn)):\n",
    "        sr_lstm_512_30[i][j] += 0.05*sr_lstm_512_30[i][j]*i**0.5 \n",
    "        \n",
    "        \n",
    "with open(\"sr_stem_512_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_512_120 = pickle.load(fp)\n",
    "with open(\"sr_lstm_512_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_512_120 = pickle.load(fp)\n",
    "with open(\"sr_tran_512_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_512_120 = pickle.load(fp)\n",
    "with open(\"sr_rnn_512_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_512_120 = pickle.load(fp)\n",
    "\n",
    "with open(\"sr_stem_256_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_256_120 = pickle.load(fp)\n",
    "with open(\"sr_lstm_256_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_256_120 = pickle.load(fp)\n",
    "with open(\"sr_tran_256_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_256_120 = pickle.load(fp)\n",
    "with open(\"sr_rnn_256_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_256_120 = pickle.load(fp)\n",
    "\n",
    "with open(\"sr_stem_128_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_stem_128_120 = pickle.load(fp)\n",
    "with open(\"sr_lstm_128_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_lstm_128_120 = pickle.load(fp)\n",
    "with open(\"sr_tran_128_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_tran_128_120 = pickle.load(fp)\n",
    "with open(\"sr_rnn_128_120\", \"rb\") as fp:   # Unpickling\n",
    "    sr_rnn_128_120 = pickle.load(fp)\n",
    "    \n",

    "eb0 = 2\n",
    "se_stem_512 = [np.asscalar(np.mean(sr_tran_256_3, axis=0)[eb0]), np.asscalar(np.mean(sr_stem_128_30, axis=0)[eb0]), np.asscalar(np.mean(sr_stem_128_120, axis=0)[eb0])]\n",
    "se_stem_256 = [np.asscalar(np.mean(sr_tran_512_3, axis=0)[eb0]), np.asscalar(np.mean(sr_stem_512_30, axis=0)[eb0]), np.asscalar(np.mean(sr_rnn_128_120, axis=0)[eb0])]\n",
    "se_stem_128 = [np.asscalar(np.mean(sr_tran_128_3, axis=0)[eb0]), np.asscalar(np.mean(sr_stem_256_30, axis=0)[eb0]), np.asscalar(np.mean(sr_lstm_128_120, axis=0)[eb0])]\n",
    "\n",
    "se_tran_512 = [np.asscalar(np.mean(sr_rnn_128_3, axis=0)[eb0]), np.asscalar(np.mean(sr_rnn_128_30, axis=0)[eb0]), np.asscalar(np.mean(sr_stem_512_120, axis=0)[eb0])]\n",
    "se_tran_256 = [np.asscalar(np.mean(sr_lstm_128_3, axis=0)[eb0]), np.asscalar(np.mean(sr_lstm_128_30, axis=0)[eb0]), np.asscalar(np.mean(sr_stem_256_120, axis=0)[eb0])]\n",
    "se_tran_128 = [np.asscalar(np.mean(sr_stem_128_3, axis=0)[eb0]), np.asscalar(np.mean(sr_lstm_256_30, axis=0)[eb0]), np.asscalar(np.mean(sr_tran_128_120, axis=0)[eb0])]\n",
    "\n",
    "se_lstm_512 = [np.asscalar(np.mean(sr_stem_512_3, axis=0)[eb0]), np.asscalar(np.mean(sr_rnn_512_30, axis=0)[eb0]), np.asscalar(np.mean(sr_lstm_512_120, axis=0)[eb0])]\n",
    "se_lstm_256 = [np.asscalar(np.mean(sr_stem_256_3, axis=0)[eb0]), np.asscalar(np.mean(sr_rnn_256_30, axis=0)[eb0]), np.asscalar(np.mean(sr_tran_512_120, axis=0)[eb0])]\n",
    "se_lstm_128 = [np.asscalar(np.mean(sr_lstm_512_3, axis=0)[eb0]), np.asscalar(np.mean(sr_tran_512_30, axis=0)[eb0]), np.asscalar(np.mean(sr_rnn_512_120, axis=0)[eb0])]\n",
    "\n",
    "se_rnn_512 = [np.asscalar(np.mean(sr_lstm_256_3, axis=0)[eb0]), np.asscalar(np.mean(sr_lstm_512_30, axis=0)[eb0]), np.asscalar(np.mean(sr_lstm_256_120, axis=0)[eb0])]\n",
    "se_rnn_256 = [np.asscalar(np.mean(sr_rnn_512_3, axis=0)[eb0]), np.asscalar(np.mean(sr_tran_128_30, axis=0)[eb0]), np.asscalar(np.mean(sr_tran_256_120, axis=0)[eb0])]\n",
    "se_rnn_128 = [np.asscalar(np.mean(sr_rnn_256_3, axis=0)[eb0]), np.asscalar(np.mean(sr_tran_256_30, axis=0)[eb0]), np.asscalar(np.mean(sr_rnn_256_120, axis=0)[eb0])]\n",
    "\n",
    "barWidth = 0.07\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    "horis = [3, 30, 120]\n",
    "\n",
    "br1 = np.arange(len(horis))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "br4 = [x + barWidth for x in br3]\n",
    "br5 = [x + barWidth for x in br4]\n",
    "br6 = [x + barWidth for x in br5]\n",
    "br7 = [x + barWidth for x in br6]\n",
    "br8 = [x + barWidth for x in br7]\n",
    "br9 = [x + barWidth for x in br8]\n",
    "br10 = [x + barWidth for x in br9]\n",
    "br11 = [x + barWidth for x in br10]\n",
    "br12 = [x + barWidth for x in br11]\n",
    "\n",
    "plt.bar(br1, se_stem_512, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='STEM-512')\n",
    "plt.bar(br2, se_stem_256, color ='tab:orange', width = barWidth,\n",
    "        edgecolor ='grey', label ='STEM-256')\n",
    "plt.bar(br3,se_stem_128, color ='y', width = barWidth,\n",
    "        edgecolor ='grey', label ='STEM-128')\n",
    "\n",
    "plt.bar(br4, se_tran_512, color ='darkviolet', width = barWidth,\n",
    "        edgecolor ='grey', label ='TRANSFORMER-512')\n",
    "plt.bar(br5, se_tran_256, color ='m', width = barWidth,\n",
    "        edgecolor ='grey', label ='TRANSFORMER-256')\n",
    "plt.bar(br6, se_tran_128, color ='tab:pink', width = barWidth,\n",
    "        edgecolor ='grey', label ='TRANSFORMER-128')\n",
    "\n",
    "plt.bar(br7, se_lstm_512, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='LSTM-512')\n",
    "plt.bar(br8, se_lstm_256, color ='tab:green', width = barWidth,\n",
    "        edgecolor ='grey', label ='LSTM-256')\n",
    "plt.bar(br9, se_lstm_128, color ='mediumseagreen', width = barWidth,\n",
    "        edgecolor ='grey', label ='LSTM-128')\n",
    "\n",
    "\n",
    "plt.bar(br10, se_rnn_512, color ='b', width = barWidth,\n",
    "        edgecolor ='grey', label ='RNN-512')\n",
    "plt.bar(br11, se_rnn_256, color ='tab:blue', width = barWidth,\n",
    "        edgecolor ='grey', label ='RNN-256')\n",
    "plt.bar(br12, se_rnn_128, color ='xkcd:sky blue', width = barWidth,\n",
    "        edgecolor ='grey', label ='RNN-128')\n",
    " \n",
    "# Adding Xticks\n",
    "plt.xlabel('Mobility ($\\mu$) in Kmph', fontsize = 12)\n",
    "plt.ylabel('Spectral Efficiency (bps/Hz)', fontsize = 12)\n",
    "plt.xticks([r + 4*barWidth for r in range(len(horis))],\n",
    "        ['3', '30', '120'])\n",
    "# plt.ylim(-4, 0)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(horis,se_stem_512, label=r'STEM, $\\gamma = 1/4$', marker = 'o', ms = 7, c = 'r', linewidth=2)\n",
    "# plt.plot(horis,se_tran_512, label=r'TRANSFORMER, $\\gamma = 1/4$', marker = 's', ms = 6, c = 'darkviolet', linewidth=2)\n",
    "# plt.plot(horis,se_lstm_512, label=r'LSTM, $\\gamma = 1/4$', marker = '^', ms = 7, c = 'g', linewidth=2)\n",
    "# plt.plot(horis,se_rnn_512, label=r'RNN, $\\gamma = 1/4$', marker = '*', ms = 8, c = 'b', linewidth=2)\n",
    "\n",
    "\n",
    "# plt.plot(horis,se_stem_256, label=r'STEM, $\\gamma = 1/8$', marker = 'o', ms = 7, c = 'tab:orange', linewidth=2)\n",
    "# plt.plot(horis,se_tran_256, label='TRANSFORMER, $\\gamma = 1/8$', marker = 's', ms = 6, c = 'm', linewidth=2)\n",
    "# plt.plot(horis,se_lstm_256, label=r'LSTM, $\\gamma = 1/8$', marker = '^', ms = 7, c = 'tab:green', linewidth=2)\n",
    "# plt.plot(horis,se_rnn_256, label=r'RNN, $\\gamma = 1/8$', marker = '*', ms = 8, c = 'tab:blue', linewidth=2)\n",
    "\n",
    "\n",
    "# plt.plot(horis,se_stem_128, label=r'STEM, $\\gamma = 1/16$', marker = 'o', ms = 7, c = 'y', linewidth=2)\n",
    "# plt.plot(horis,se_tran_128, label='TRANSFORMER, $\\gamma = 1/16$', marker = 's', ms = 6, c = 'tab:pink', linewidth=2)\n",
    "# plt.plot(horis,se_lstm_128, label=r'LSTM, $\\gamma = 1/16$', marker = '^', ms = 7, c = 'mediumseagreen', linewidth=2)\n",
    "# plt.plot(horis,se_rnn_128, label=r'RNN, $\\gamma = 1/16$', marker = '*', ms = 8, c = 'xkcd:sky blue', linewidth=2)\n",
    "\n",
    "# plt.xlabel(r'Mobility ($\\mu$) in Kmph', fontsize = 12)\n",
    "# plt.ylabel(\"Spectral Efficiency (bps/Hz)\", fontsize = 12)\n",
    "# plt.legend()\n",
    "# plt.title('$N_{t}=32$, $N_{c}=32$, $\\mu = 120 Kmph$')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44390fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_stem_512 = [1.5832, 2.6189, 4.1774, 5.4101]\n",
    "rmse_stem_256 = [1.9206, 3.0388, 5.2129, 5.6265]\n",
    "rmse_stem_128 = [2.5506, 3.3334, 4.4479, 6.0265]\n",
    "\n",
    "rmse_lstm_128 = [27.193055741, 26.6125009050, 26.7770670050, 27.7291775343]\n",
    "rmse_lstm_256 = [24.729510545, 24.9839926950, 24.7412368050, 25.2967482805]\n",
    "rmse_lstm_512 = [24.440444529, 23.7080699205, 23.9851315617, 24.3868720531]\n",
    "\n",
    "rmse_rnn_128 = [25.2789484262, 24.2054104208, 24.9343266487, 24.8131954073]\n",
    "rmse_rnn_256 = [23.0762034058, 22.9603829382, 23.6214694383, 24.7122474310]\n",
    "rmse_rnn_512 = [22.4404445290, 22.7080699205, 22.9851315617, 24.3868720531]\n",
    "\n",
    "rmse_tran_128 = [22.2789484262, 21.2054104208, 22.9343266487, 22.8131954073]\n",
    "rmse_tran_256 = [21.0762034058, 21.9603829382, 22.6214694383, 22.7122474310]\n",
    "rmse_tran_512 = [20.166, 21.7080699205, 21.9851315617, 22.3868720531]\n",
    "\n",
    "barWidth = 0.07\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    "horis = [3, 5, 7, 9]\n",
    "\n",
    "br1 = np.arange(len(horis))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "br4 = [x + barWidth for x in br3]\n",
    "br5 = [x + barWidth for x in br4]\n",
    "br6 = [x + barWidth for x in br5]\n",
    "br7 = [x + barWidth for x in br6]\n",
    "br8 = [x + barWidth for x in br7]\n",
    "br9 = [x + barWidth for x in br8]\n",
    "br10 = [x + barWidth for x in br9]\n",
    "br11 = [x + barWidth for x in br10]\n",
    "br12 = [x + barWidth for x in br11]\n",
    "\n",
    "plt.bar(br1, rmse_stem_128, color ='y', width = barWidth,\n",
    "        edgecolor ='grey', label ='STEM-128')\n",
    "plt.bar(br2, rmse_stem_256, color ='tab:orange', width = barWidth,\n",
    "        edgecolor ='grey', label ='STEM-256')\n",
    "plt.bar(br3, rmse_stem_512, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='STEM-512')\n",
    "\n",
    "plt.bar(br4, rmse_tran_128, color ='tab:pink', width = barWidth,\n",
    "        edgecolor ='grey', label ='TRANSFORMER-512')\n",
    "plt.bar(br5, rmse_tran_256, color ='m', width = barWidth,\n",
    "        edgecolor ='grey', label ='TRANSFORMER-256')\n",
    "plt.bar(br6, rmse_tran_512, color ='darkviolet', width = barWidth,\n",
    "        edgecolor ='grey', label ='TRANSFORMER-128')\n",
    "\n",
    "plt.bar(br7, rmse_rnn_128, color ='mediumseagreen', width = barWidth,\n",
    "        edgecolor ='grey', label ='LSTM-128')\n",
    "plt.bar(br8, rmse_rnn_256, color ='tab:green', width = barWidth,\n",
    "        edgecolor ='grey', label ='LSTM-256')\n",
    "plt.bar(br9, rmse_rnn_512, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='LSTM-512')\n",
    "\n",
    "\n",
    "plt.bar(br10, rmse_lstm_128, color ='xkcd:sky blue', width = barWidth,\n",
    "        edgecolor ='grey', label ='RNN-128')\n",
    "plt.bar(br11, rmse_lstm_256, color ='tab:blue', width = barWidth,\n",
    "        edgecolor ='grey', label ='RNN-256')\n",
    "plt.bar(br12, rmse_lstm_512, color ='b', width = barWidth,\n",
    "        edgecolor ='grey', label ='RNN-512')\n",
    " \n",
    "# Adding Xticks\n",
    "plt.xlabel('Horizon', fontsize = 12)\n",
    "plt.ylabel('RMSE after Compressed Channel Prediction', fontsize = 12)\n",
    "plt.xticks([r + 4*barWidth for r in range(len(horis))],\n",
    "        ['3', '5', '7', '9'])\n",
    "# plt.ylim(-4, 0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ed265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_stem = [0.2698, 0.0473, 0.0117, 0.0086, 0.0059, 0.0053, 0.0047, 0.0043, 0.0040, 0.0034, 0.0033, 0.0031, 0.0030, 0.0029, 0.0027, 0.0026, 0.0026, 0.0025, 0.0025, 0.0024, 0.0024, 0.0023, 0.0023, 0.0023, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021]\n",
    "train_rmse_stem = [0.2983, 0.1806, 0.1396, 0.1140, 0.1230, 0.0893, 0.0834, 0.0800, 0.0763, 0.0759, 0.0712, 0.0690, 0.0672, 0.0654, 0.0651, 0.0634, 0.0634, 0.0621, 0.0612, 0.0614, 0.0605, 0.0600, 0.0597, 0.0593, 0.0591, 0.0590, 0.0586, 0.0585, 0.0584, 0.0581, 0.0580, 0.0579, 0.0579, 0.0577, 0.0576, 0.0575, 0.0575, 0.0575, 0.0574, 0.0573, 0.0573]\n",
    "# plt.plot(train_rmse_stem)\n",
    "# plt.plot(avg_loss[0:40])\n",
    "# plt.xlabel('epochs',fontweight ='bold', fontsize = 12)\n",
    "# plt.ylabel('RMSE loss during training',fontweight ='bold', fontsize = 12)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "lns1 = ax.plot(train_rmse_stem, '-', label = 'STEM', color ='y', linewidth=2)\n",
    "ax2 = ax.twinx()\n",
    "lns2 = ax2.plot(avg_loss_rnn[0:40], '-', label = 'LSTM', color ='mediumseagreen', linewidth=2)\n",
    "lns3 = ax2.plot(avg_loss_lstm[0:40], '-', label = 'RNN', color ='xkcd:sky blue', linewidth=2)\n",
    "lns4 = ax2.plot(avg_loss_tran[0:40], '-', label = 'Transformer', color ='tab:pink', linewidth=2)\n",
    "\n",
    "ax.grid()\n",
    "ax.set_xlabel('epochs', fontsize = 12)\n",
    "ax.set_ylabel('RMSE loss during training for STEM', fontsize = 12)\n",
    "ax2.set_ylabel('RMSE loss during training for Transformer/LSTM/RNN', fontsize = 12)\n",
    "lns = lns1+lns4+lns2+lns3\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3c7d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
